{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure nltk\n",
    "\n",
    "import nltk\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load text data from a file and produce a list of token lists\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    \n",
    "    with open('../Sonnet_ngram/THE_SONNETS.txt') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip().lower()    \n",
    "            if len(line) > 3:\n",
    "                sentences.append(nltk.word_tokenize(line))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences):\n",
    "    \"\"\"\n",
    "    Take a list of sentences and return a vocab\n",
    "    \"\"\"\n",
    "    vocab = set()\n",
    "    for i in sentences:\n",
    "        for k in i:\n",
    "            vocab.add(k)\n",
    "    vocab.add('<s>')\n",
    "    vocab.add('</s>')\n",
    "    \n",
    "    return list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngrams(n, sentences):\n",
    "    \"\"\"\n",
    "    Take a list of unpadded sentences and create all n-grams as specified by the argument \"n\" for each sentence\n",
    "    \"\"\"\n",
    "    all_ngrams = []\n",
    "    for i in sentences:\n",
    "        paddedline = nltk.lm.preprocessing.pad_both_ends(i, n)\n",
    "        ngrams = nltk.ngrams(paddedline, n)\n",
    "        #print(list(ngrams))\n",
    "        ngrams= list(ngrams)\n",
    "        all_ngrams.append(ngrams)\n",
    "    \n",
    "    return all_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_next_token(start_tokens=(\"<s>\", ) * 3):\n",
    "    \"\"\"\n",
    "    Take some starting tokens and produce the most likely token that follows under a bi-gram model\n",
    "    \"\"\"\n",
    "    \n",
    "    lst = []\n",
    "    for i in build_ngrams(2, load_data()):\n",
    "        for k in i:\n",
    "            if k[0] == start_tokens[-1]:\n",
    "                lst.append(k[1])\n",
    "    next_token = max(lst, key=lst.count)\n",
    "    prob = lst.count(next_token)/len(lst)\n",
    "\n",
    "    \n",
    "    return next_token, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "\n",
    "def train_ngram_lm(n):\n",
    "    \"\"\"\n",
    "    Train a n-gram language model as specified by the argument \"n\"\n",
    "    \"\"\"\n",
    "    \n",
    "    lm = MLE(n)\n",
    "    lm.fit(build_ngrams(n, load_data()), build_vocab(load_data()))\n",
    "    \n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thy adverse party is thy good report .\n",
      "while comments of your fair eyes , even\n",
      "unlearned in the mouths of men .\n",
      "so you oâ€™er-green my bad angel fire my\n",
      "show me your image in some perfumes is\n",
      "when you entombed in menâ€™s eyes and womenâ€™s\n",
      "counting no old thing old ,\n",
      "then happy i that love is as a\n",
      "nativity once in the living record of your\n",
      "and dost him grace when clouds do blot\n",
      "and live no more be grieved at that\n",
      "that i might teach thee how thy precious\n",
      "lean penury within that pen doth dwell ,\n",
      "in vowing new hate after new love bearing\n"
     ]
    }
   ],
   "source": [
    "# Every time it runs, depending on how drunk it is, a different sonnet is written. \n",
    "n = 3\n",
    "num_lines = 14\n",
    "num_words_per_line = 8\n",
    "text_seed = [\"<s>\"] * (n - 1)\n",
    "\n",
    "lm = train_ngram_lm(n)\n",
    "\n",
    "sonnet = []\n",
    "while len(sonnet) < num_lines:\n",
    "    while True:  # keep generating a line until success\n",
    "        try:\n",
    "            line = lm.generate(num_words_per_line, text_seed=text_seed)\n",
    "        except ValueError:  # the generation is not always successful. need to capture exceptions\n",
    "            continue\n",
    "        else:\n",
    "            line = [x for x in line if x not in [\"<s>\", \"</s>\"]]\n",
    "            sonnet.append(\" \".join(line))\n",
    "            break\n",
    "\n",
    "# pretty-print your sonnet\n",
    "print(\"\\n\".join(sonnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
